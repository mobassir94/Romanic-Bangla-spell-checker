{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fancy abbreviations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKRuyI2ga1tP"
      },
      "source": [
        "in this notebook i am trying to use this solution : https://medium.com/swlh/a-machine-learning-model-to-understand-fancy-abbreviations-trained-on-tolkien-36601b73ecbb  and https://stackoverflow.com/questions/43510778/python-how-to-intuit-word-from-abbreviated-text-using-nlp and code from : https://github.com/avidale/weirdMath/blob/master/nlp/abbreviation_spellchecker_english.ipynb on a romanic bangla spellchecker task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZE40m_ejE1"
      },
      "source": [
        "Dataset link : https://www.kaggle.com/mobassir/romanic-bangla-songs-lyrics or https://github.com/mobassir94/Romanic-Bangla-spell-checker/blob/main/RomanicBanglaSongsLyrics.txt "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HibpiDa8AqPy"
      },
      "source": [
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class LanguageNgramModel:\n",
        "    \"\"\" Remember and predict which letters usually follows which. \"\"\"\n",
        "    def __init__(self, order=1, smoothing=1.0, recursive=0.001):\n",
        "        self.order = order\n",
        "        self.smoothing = smoothing\n",
        "        self.recursive = recursive\n",
        "    \n",
        "    def fit(self, corpus):\n",
        "        \"\"\" Estimate all counts on a text \"\"\"\n",
        "        self.counter_ = defaultdict(lambda: Counter())\n",
        "        self.unigrams_ = Counter()\n",
        "        self.vocabulary_ = set()\n",
        "        for i, token in enumerate(corpus[self.order:]):\n",
        "            context = corpus[i:(i+self.order)]\n",
        "            self.counter_[context][token] += 1\n",
        "            self.unigrams_[token] +=1\n",
        "            self.vocabulary_.add(token)\n",
        "        self.vocabulary_ = sorted(list(self.vocabulary_))\n",
        "        if self.recursive > 0 and self.order > 0:\n",
        "            self.child_ = LanguageNgramModel(self.order-1, self.smoothing, self.recursive)\n",
        "            self.child_.fit(corpus)\n",
        "            \n",
        "    def get_counts(self, context):\n",
        "        \"\"\" Get smoothed count of each letter appearing after context \"\"\"\n",
        "        if self.order:\n",
        "            local = context[-self.order:]\n",
        "        else:\n",
        "            local = ''\n",
        "        freq_dict = self.counter_[local]\n",
        "        freq = pd.Series(index=self.vocabulary_)\n",
        "        for i, token in enumerate(self.vocabulary_):\n",
        "            freq[token] = freq_dict[token] + self.smoothing\n",
        "        if self.recursive > 0 and self.order > 0:\n",
        "            child_freq = self.child_.get_counts(context) * self.recursive\n",
        "            freq += child_freq\n",
        "        return freq\n",
        "    \n",
        "    def predict_proba(self, context):\n",
        "        \"\"\" Get smoothed probability of each letter appearing after context \"\"\"\n",
        "        counts = self.get_counts(context)\n",
        "        return counts / counts.sum()\n",
        "    \n",
        "    def single_log_proba(self, context, continuation):\n",
        "        \"\"\" Estimate log-probability that context is followed by continuation \"\"\"\n",
        "        result = 0.0\n",
        "        for token in continuation:\n",
        "            result += np.log(self.predict_proba(context)[token])\n",
        "            context += token\n",
        "        return result\n",
        "    \n",
        "    def single_proba(self, context, continuation):\n",
        "        \"\"\" Estimate probability that context is followed by continuation \"\"\"\n",
        "        return np.exp(self.single_log_proba(context, continuation))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXtR1F2TAuX4"
      },
      "source": [
        "class MissingLetterModel:\n",
        "    \"\"\" Remember and predict which letters are usually missing. \"\"\"\n",
        "    def __init__(self, order=0, smoothing_missed=0.3, smoothing_total=1.0):\n",
        "        self.order = order\n",
        "        self.smoothing_missed = smoothing_missed\n",
        "        self.smoothing_total = smoothing_total\n",
        "    def fit(self, sentence_pairs):\n",
        "        self.missed_counter_ = defaultdict(lambda: Counter())\n",
        "        self.total_counter_ = defaultdict(lambda: Counter())\n",
        "        for (original, observed) in sentence_pairs:\n",
        "            for i, (original_letter, observed_letter) in enumerate(zip(original[self.order:], observed[self.order:])):\n",
        "                context = original[i:(i+self.order)]\n",
        "                if observed_letter == '-':\n",
        "                    self.missed_counter_[context][original_letter] += 1\n",
        "                self.total_counter_[context][original_letter] += 1 \n",
        "    def predict_proba(self, context, last_letter):\n",
        "        \"\"\" Estimate probability that last_letter after context is missed \"\"\"\n",
        "        if self.order:\n",
        "            local = context[-self.order:]\n",
        "        else:\n",
        "            local = ''\n",
        "        missed_freq = self.missed_counter_[local][last_letter] + self.smoothing_missed\n",
        "        total_freq = self.total_counter_[local][last_letter] + self.smoothing_total\n",
        "        return missed_freq / total_freq\n",
        "    \n",
        "    def single_log_proba(self, context, continuation, actual=None):\n",
        "        \"\"\" Estimate log-probability of continuaton being distorted to actual after context. \n",
        "        If actual is None, assume no distortion\n",
        "        \"\"\"\n",
        "        if not actual:\n",
        "            actual = continuation\n",
        "        result = 0.0\n",
        "        for orig_token, act_token in zip(continuation, actual):\n",
        "            pp = self.predict_proba(context, orig_token)\n",
        "            if act_token == '-':\n",
        "                pp = 1 - pp\n",
        "            result += np.log(pp)\n",
        "            context += orig_token\n",
        "        return result\n",
        "    \n",
        "    def single_proba(self, context, continuation, actual=None):\n",
        "        \"\"\" Estimate probability of continuaton being distorted to actual after context. \n",
        "        If actual is None, assume no distortion\n",
        "        \"\"\"\n",
        "        return np.exp(self.single_log_proba(context, continuation, actual))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7IgQlRCAx40",
        "outputId": "c69ddfb7-a6f0-418a-d1ba-dce0876b4d19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lang_model = LanguageNgramModel(1)\n",
        "lang_model.fit(' abracadabra ')\n",
        "lang_model.predict_proba(' bra')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0.181777\n",
              "a    0.091297\n",
              "b    0.272529\n",
              "c    0.181686\n",
              "d    0.181686\n",
              "r    0.091025\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y07ZGLMdA0qp",
        "outputId": "f6dd043d-cd6c-4b7e-e560-8568fee113fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "missed_model = MissingLetterModel(0)\n",
        "missed_model.fit([('abracadabra', 'abr-c-d-br-')]) \n",
        "missed_model.predict_proba('abr', 'a'), missed_model.predict_proba('abr', 'b')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7166666666666667, 0.09999999999999999)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6vDHc2_A4H1",
        "outputId": "0ae7909d-1822-4219-f5dc-61a3f9e8987c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "missed_model.single_proba('', 'abra', 'abr-')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0020305555555555532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCSneKNIA6wL"
      },
      "source": [
        "from heapq import heappush, heappop"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oApZuoTjA-A5",
        "outputId": "632756b7-78bb-4a3c-a5b9-7779c2cf994f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def generate_options(prefix_proba, prefix, suffix, lang_model, missed_model, optimism=0.5, cache=None):\n",
        "    options = []\n",
        "    for letter in lang_model.vocabulary_ + ['']:\n",
        "        if letter:  # assume a missing letter\n",
        "            next_letter = letter\n",
        "            new_suffix = suffix\n",
        "            new_prefix = prefix + next_letter\n",
        "            proba_missing_state = - np.log(missed_model.predict_proba(prefix, letter))\n",
        "        else:  # assume no missing letter\n",
        "            next_letter = suffix[0]\n",
        "            new_suffix = suffix[1:]\n",
        "            new_prefix = prefix + next_letter\n",
        "            proba_missing_state = - np.log((1 - missed_model.predict_proba(prefix, next_letter)))\n",
        "        proba_next_letter = - np.log(lang_model.single_proba(prefix, next_letter))\n",
        "        if cache:\n",
        "            proba_suffix = cache[len(new_suffix)] * optimism\n",
        "        else:\n",
        "            proba_suffix = - np.log(lang_model.single_proba(new_prefix, new_suffix)) * optimism\n",
        "        proba = prefix_proba + proba_next_letter + proba_missing_state + proba_suffix\n",
        "        options.append((proba, new_prefix, new_suffix, letter, proba_suffix))\n",
        "    return options\n",
        "print(generate_options(0, ' ', 'brac ', lang_model, missed_model))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(6.929663174828117, '  ', 'brac ', ' ', 3.7800651217336947), (5.042879645338754, ' a', 'brac ', 'a', 3.4572571306016755), (8.09487194753453, ' b', 'brac ', 'b', 3.846661605771999), (7.623807861705187, ' c', 'brac ', 'c', 3.7800651217336947), (7.623807861705187, ' d', 'brac ', 'd', 3.7800651217336947), (8.09487194753453, ' r', 'brac ', 'r', 3.846661605771999), (4.858238261775765, ' b', 'rac ', '', 2.8072524973494524)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRR_JL0EBBL3"
      },
      "source": [
        "def noisy_channel(word, lang_model, missed_model, freedom=1.0, max_attempts=1000, optimism=0.1, verbose=True):\n",
        "    query = word + ' '\n",
        "    prefix = ' '\n",
        "    prefix_proba = 0.0\n",
        "    suffix = query\n",
        "    full_origin_logprob = -lang_model.single_log_proba(prefix, query)\n",
        "    no_missing_logprob = -missed_model.single_log_proba(prefix, query)\n",
        "    best_logprob = full_origin_logprob + no_missing_logprob\n",
        "    # add empty beginning to the heap\n",
        "    heap = [(best_logprob * optimism, prefix, suffix, '', best_logprob * optimism)]\n",
        "    # add the default option (no missing letters) to candidates\n",
        "    candidates = [(best_logprob, prefix + query, '', None, 0.0)]\n",
        "    if verbose:\n",
        "        # todo: include distortion probability\n",
        "        print('baseline score is', best_logprob)\n",
        "    # prepare cache for suffixes (the slowest operation)\n",
        "    cache = {}\n",
        "    for i in range(len(query)+1):\n",
        "        future_suffix = query[:i]\n",
        "        cache[len(future_suffix)] = -lang_model.single_log_proba('', future_suffix) # rough approximation\n",
        "        cache[len(future_suffix)] += -missed_model.single_log_proba('', future_suffix) # at least add missingness\n",
        "    \n",
        "    for i in range(max_attempts):\n",
        "        if not heap:\n",
        "            break\n",
        "        next_best = heappop(heap)\n",
        "        if verbose:\n",
        "            print(next_best)\n",
        "        if next_best[2] == '':  # it is a leaf\n",
        "            # this is the best leaf as far, add it to candidates\n",
        "            if next_best[0] <= best_logprob + freedom:\n",
        "                candidates.append(next_best)\n",
        "                # update the best likelihood\n",
        "                if next_best[0] < best_logprob:\n",
        "                    best_logprob = next_best[0]\n",
        "        else: # it is not a leaf - generate more options\n",
        "            prefix_proba = next_best[0] - next_best[4] # all proba estimate minus suffix\n",
        "            prefix = next_best[1]\n",
        "            suffix = next_best[2]\n",
        "            new_options = generate_options(prefix_proba, prefix, suffix, lang_model, missed_model, optimism, cache)\n",
        "            # add only the solution potentioally no worse than the best + freedom\n",
        "            for new_option in new_options: \n",
        "                if new_option[0] < best_logprob + freedom:\n",
        "                    heappush(heap, new_option)\n",
        "    if verbose:\n",
        "        print('heap size is', len(heap), 'after', i, 'iterations')\n",
        "    result = {}\n",
        "    for candidate in candidates:\n",
        "        if candidate[0] <= best_logprob + freedom:\n",
        "            result[candidate[1][1:-1]] = candidate[0]\n",
        "    return result"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AgC4bq7BFKs",
        "outputId": "a6523c82-7d61-4bbb-f388-e70389c7a338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result = noisy_channel('brc', lang_model, missed_model, freedom=2.0, optimism=0.5, verbose=True)\n",
        "print(result)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baseline score is 14.659531132722798\n",
            "(7.329765566361399, ' ', 'brc ', '', 7.329765566361399)\n",
            "(7.729102491649175, ' b', 'rc ', '', 5.6781167272228625)\n",
            "(6.82819709010665, ' br', 'c ', '', 3.689648873198813)\n",
            "(7.4281382278577714, ' brc', ' ', '', 2.0472553582899407)\n",
            "(7.68318306227505, ' brc ', '', '', -0.0)\n",
            "(8.142544971129297, ' bra', 'c ', 'a', 3.689648873198813)\n",
            "(8.36814476033081, ' brac', ' ', '', 2.0472553582899407)\n",
            "(8.623189594748087, ' brac ', '', '', -0.0)\n",
            "(8.838538268507152, ' a', 'brc ', 'a', 7.252915753770074)\n",
            "(8.669109024122214, ' ab', 'rc ', '', 5.6781167272228625)\n",
            "(7.768203622579689, ' abr', 'c ', '', 3.689648873198813)\n",
            "(8.36814476033081, ' abrc', ' ', '', 2.0472553582899407)\n",
            "(8.623189594748087, ' abrc ', '', '', -0.0)\n",
            "(9.013760742594851, ' brca', ' ', 'a', 2.0472553582899407)\n",
            "(9.028155327065601, ' brca ', '', '', -0.0)\n",
            "(9.082551503602335, ' abra', 'c ', 'a', 3.689648873198813)\n",
            "(9.30815129280385, ' abrac', ' ', '', 2.0472553582899407)\n",
            "(9.563196127221126, ' abrac ', '', '', -0.0)\n",
            "(10.11098811127768, ' br ', 'c ', ' ', 3.689648873198813)\n",
            "(10.138078592325058, ' ba', 'rc ', 'a', 5.6781167272228625)\n",
            "(10.402513806864496, '  ', 'brc ', ' ', 7.252915753770074)\n",
            "(10.577736280952195, ' brc ', ' ', ' ', 2.0472553582899407)\n",
            "(10.80513279815475, ' brc', 'c ', 'c', 3.689648873198813)\n",
            "(10.80513279815475, ' brd', 'c ', 'd', 3.689648873198813)\n",
            "(11.011893512820205, ' b ', 'rc ', ' ', 5.6781167272228625)\n",
            "(11.013889521466918, ' br', 'rc ', 'r', 5.6781167272228625)\n",
            "(11.096658493741566, ' c', 'brc ', 'c', 7.252915753770074)\n",
            "(11.096658493741566, ' d', 'brc ', 'd', 7.252915753770074)\n",
            "(11.209600399945788, ' brb', 'c ', 'b', 3.689648873198813)\n",
            "(11.209600399945788, ' brr', 'c ', 'r', 3.689648873198813)\n",
            "(11.271880967829265, ' brcc', ' ', 'c', 2.0472553582899407)\n",
            "(11.271880967829265, ' brcd', ' ', 'd', 2.0472553582899407)\n",
            "(11.501126095532605, ' b', 'brc ', 'b', 7.252915753770074)\n",
            "(11.501126095532605, ' r', 'brc ', 'r', 7.252915753770074)\n",
            "(11.676348569620306, ' brcb', ' ', 'b', 2.0472553582899407)\n",
            "(11.676348569620306, ' brcr', ' ', 'r', 2.0472553582899407)\n",
            "(11.706038199697275, ' bc', 'rc ', 'c', 5.6781167272228625)\n",
            "(11.706038199697275, ' bd', 'rc ', 'd', 5.6781167272228625)\n",
            "(12.110505801488314, ' bb', 'rc ', 'b', 5.6781167272228625)\n",
            "heap size is 0 after 39 iterations\n",
            "{'brc': 7.68318306227505, 'brac': 8.623189594748087, 'abrc': 8.623189594748087, 'brca': 9.028155327065601, 'abrac': 9.563196127221126}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqDZklW2BHz1",
        "outputId": "92f0f000-34b2-435a-f27c-230b2f188fa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#https://stackoverflow.com/questions/42339876/error-unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-in\n",
        "\n",
        "path = '/content/RomanicBanglaSongsLyrics.txt' #'/content/02 - The Two Towers.txt'\n",
        "\n",
        "#with open(path , \"rb\") as f: # encoding = 'utf-8'\n",
        "with open(path, encoding=\"utf8\", errors='ignore') as f:\n",
        "  text = f.read()\n",
        "import re\n",
        "text2 = re.sub(r'[^a-z ]+', '', text.lower().replace('\\n', ' '))\n",
        "print(text2[0:100])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "indubala go o tumi kon akashe thako joshna kaare makho kaar uthone poro jhoriya dubiya morilam moriy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj7fdAVeBK3p",
        "outputId": "952db14f-01f8-43eb-fd0e-8e3156c1a5c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "all_letters = ''.join(list(sorted(list(set(text2)))))\n",
        "print(repr(all_letters))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "' abcdefghijklmnoprstuvwxyz'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bngkREEHBOze"
      },
      "source": [
        "missing_set = [\n",
        "] + [(all_letters, '-' * len(all_letters))] * 3 + [(all_letters, all_letters)] * 10 + [('aeiouy', '------')] * 30"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL3aKbw0BSSe",
        "outputId": "e6fefb0a-eba2-47e3-b4f8-c7b00288b794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(5):\n",
        "    tmp = LanguageNgramModel(i, 1.0, 0.001)\n",
        "    tmp.fit(text2[0:-5000])\n",
        "    print(i, tmp.single_log_proba(' ', text2[-5000:]))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 -13758.807954992411\n",
            "1 -11061.652624343682\n",
            "2 -10221.536405370183\n",
            "3 -9850.448507206293\n",
            "4 -10931.706338065407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3v7T0O6BU5o"
      },
      "source": [
        "big_lang_m = LanguageNgramModel(4, 0.001, 0.01)\n",
        "big_lang_m.fit(text2)\n",
        "big_err_m = MissingLetterModel(0, 0.1)\n",
        "big_err_m.fit(missing_set)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pZZNF-IBW5w",
        "outputId": "42339eaf-514f-43a1-fd83-b05c468b5c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "noisy_channel('sm', big_lang_m, big_err_m, max_attempts=10000, optimism=0.9, freedom=3.0, verbose=False)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sm': 12.720902147980569,\n",
              " 'smi': 13.159121250759666,\n",
              " 'sms': 12.42163896407554,\n",
              " 'somo': 11.903848945026619,\n",
              " 'somoy': 10.248452872881996}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JAVXjGMBcU-",
        "outputId": "c39be0db-c74a-45f0-a569-7058cc89d6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "noisy_channel('rng', big_lang_m, big_err_m, max_attempts=10000, optimism=0.9, freedom=3.0, verbose=False)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rang': 11.646567206156382, 'ranga': 9.565287173166471}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9UWEJHEBgft",
        "outputId": "9bf6c447-e8c6-4113-d377-f8e2c9e0d9a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "noisy_channel('btl', big_lang_m, big_err_m, max_attempts=10000, optimism=0.9, freedom=3.0, verbose=False)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batal': 14.950405429262126,\n",
              " 'btl': 16.183094115328966,\n",
              " 'btla': 17.83495639320846,\n",
              " 'btle': 16.726944475787985,\n",
              " 'btli': 17.839844858833537,\n",
              " 'btlo': 16.715150594367298}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YTiLdbhBqDS",
        "outputId": "55908506-3ea8-498e-eb69-ab8399a6fc7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "noisy_channel('kala', big_lang_m, big_err_m, max_attempts=10000, optimism=0.9, freedom=3.0, verbose=False)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kala': 13.810543964342386}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbx2V_5UbV5r",
        "outputId": "48034e6d-9e3e-4ca3-eba7-8056af8192c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "noisy_channel('mntn', big_lang_m, big_err_m, max_attempts=10000, optimism=0.9, freedom=3.0, verbose=False)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'montron': 14.023660631079446, 'montrona': 15.547536742377916}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iipiK9_qSAJ7",
        "outputId": "b7f51f5b-bcff-4cc3-dc0b-58cf16ade604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!!apt install enchant\n",
        "!pip install pyenchant==3.0.0"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyenchant==3.0.0 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66bpw3fCcI6P"
      },
      "source": [
        "# Trying Banglish Spellchecker again using Levenshtein distance :  https://github.com/mobassir94/banglishChecker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZSXFIu1cNHH"
      },
      "source": [
        "\n",
        "ben = []\n",
        "banglishsongs = \"/content/RomanicBanglaSongsLyrics.txt\"\n",
        "text_file = open(banglishsongs, \"r\")\n",
        "lines = text_file.readlines()\n",
        "for i  in range(len(lines)):\n",
        "  data = lines[i].rstrip(\"\\n\")\n",
        "  data = data.split('\\t')\n",
        "  ben.append(data[0])\n",
        "text_file.close()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2QfqGAFcmXs",
        "outputId": "3acb8479-4604-4fda-b64c-fb4c43f1b1bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(ben)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9ENMXxfcxsc",
        "outputId": "35b61bd0-cdef-4d76-ffa3-b193100177fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ben[0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Indubala Go O..'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLkTJhUMdZRc"
      },
      "source": [
        "ben = \" \".join(ben)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vJMeDIhdCqM",
        "outputId": "5f2de7ea-3c6e-49e3-cb78-c6c0b9cc3b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein as lev\n",
        "\n",
        "def getMatch(string1,string2):\n",
        "    min_sim = .80\n",
        "    output = []\n",
        "    res = [[lev.jaro_winkler(x,y) for x in string1.split()] for y in string2.split()]\n",
        "    #print(res)\n",
        "    for x in res:\n",
        "        if max(x) >= min_sim:\n",
        "            output.append(string1.split()[x.index(max(x))])\n",
        "    return output"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (50.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD2_TenEdF2n",
        "outputId": "67355e04-c388-48b1-ba34-90746c96a7cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "getMatch(ben, \"mntn\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['monta']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV2MtpYRdqFn",
        "outputId": "be50d878-1f3b-44ca-9520-5739c759692f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "getMatch(ben, \"kala\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kala']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idrBVKdKdvKi",
        "outputId": "52e2c54d-2ccb-4fed-c9ea-20ef59b76eb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "getMatch(ben, \"rng\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rong']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_D-iVIpSVce",
        "outputId": "90bdb18c-e496-4c13-f74d-a9de979e6a42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#https://www.geeksforgeeks.org/python-spelling-checker-using-enchant/\n",
        "\n",
        "\n",
        "# import the enchant module \n",
        "import enchant \n",
        "  \n",
        "# create dictionary for the language \n",
        "# in use(en_US here) \n",
        "dict = enchant.Dict(\"en_US\") \n",
        "  \n",
        "# list of words \n",
        "words = [\"cmputr\", \"watr\", \"study\", \"wrte\"] \n",
        "  \n",
        "# find those words that may be misspelled  \n",
        "misspelled =[] \n",
        "for word in words: \n",
        "    if dict.check(word) == False: \n",
        "        misspelled.append(word) \n",
        "print(\"The misspelled words are : \" + str(misspelled)) \n",
        "  \n",
        "# suggest the correct spelling of \n",
        "# the missplelled words \n",
        "for word in misspelled: \n",
        "    print(\"Suggestion for \" + word + \" : \" + str(dict.suggest(word))) \n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The misspelled words are : ['cmputr', 'watr', 'wrte']\n",
            "Suggestion for cmputr : ['computer']\n",
            "Suggestion for watr : ['wart', 'watt', 'war', 'water']\n",
            "Suggestion for wrte : ['rte', 'write', 'wrote', 'w rte']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is8rdKH1Sa17",
        "outputId": "05fad61d-2dad-4eb1-9afd-54088f2c99fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install autocorrect\n",
        "from autocorrect import Speller\n",
        "\n",
        "spell = Speller(lang='en')\n",
        "\n",
        "print(spell('mntin'))\n",
        "print(spell('mussage'))\n",
        "print(spell('survice'))\n",
        "print(spell('hte'))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "until\n",
            "message\n",
            "service\n",
            "the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWv4CCLgVHEs",
        "outputId": "3a914e72-607b-4e14-b134-30370722dae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "nltk.download('words')\n",
        "\"would\" in words.words()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynqxbH8lWHSX"
      },
      "source": [
        " "
      ],
      "execution_count": 74,
      "outputs": []
    }
  ]
}